{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"The United States has a robust history of infrastructure development, \n",
    "characterized by continuous upgrades and expansions across key sectors. In recent years, \n",
    "there has been a growing emphasis on revitalizing aging infrastructure, with a focus on \n",
    "modernizing transportation networks, including highways, bridges, and airports. \n",
    "The country has also seen investments in renewable energy infrastructure, such as wind \n",
    "farms and solar installations, aimed at reducing reliance on traditional fossil fuels. Additionally, \n",
    "there has been a push for broadband expansion to bridge the digital divide and improve connectivity, \n",
    "especially in rural areas. Infrastructure initiatives like the American Jobs Plan highlight the commitment \n",
    "to addressing critical infrastructure needs, including water systems, broadband, and electric vehicle infrastructure. \n",
    "Overall, infrastructure growth in the U.S. underscores the importance of sustainable development and resilience in meeting the evolving needs of society and the economy.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\harshiv.bhatt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Tokenization\n",
    "nltk.download('punkt')\n",
    "#convert paragraph to sentence\n",
    "sentence=nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The United States has a robust history of infrastructure development, \\ncharacterized by continuous upgrades and expansions across key sectors.',\n",
       " 'In recent years, \\nthere has been a growing emphasis on revitalizing aging infrastructure, with a focus on \\nmodernizing transportation networks, including highways, bridges, and airports.',\n",
       " 'The country has also seen investments in renewable energy infrastructure, such as wind \\nfarms and solar installations, aimed at reducing reliance on traditional fossil fuels.',\n",
       " 'Additionally, \\nthere has been a push for broadband expansion to bridge the digital divide and improve connectivity, \\nespecially in rural areas.',\n",
       " 'Infrastructure initiatives like the American Jobs Plan highlight the commitment \\nto addressing critical infrastructure needs, including water systems, broadband, and electric vehicle infrastructure.',\n",
       " 'Overall, infrastructure growth in the U.S. underscores the importance of sustainable development and resilience in meeting the evolving needs of society and the economy.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'United', 'States', 'has', 'a', 'robust', 'history', 'of', 'infrastructure', 'development', ',', 'characterized', 'by', 'continuous', 'upgrades', 'and', 'expansions', 'across', 'key', 'sectors', '.', 'In', 'recent', 'years', ',', 'there', 'has', 'been', 'a', 'growing', 'emphasis', 'on', 'revitalizing', 'aging', 'infrastructure', ',', 'with', 'a', 'focus', 'on', 'modernizing', 'transportation', 'networks', ',', 'including', 'highways', ',', 'bridges', ',', 'and', 'airports', '.', 'The', 'country', 'has', 'also', 'seen', 'investments', 'in', 'renewable', 'energy', 'infrastructure', ',', 'such', 'as', 'wind', 'farms', 'and', 'solar', 'installations', ',', 'aimed', 'at', 'reducing', 'reliance', 'on', 'traditional', 'fossil', 'fuels', '.', 'Additionally', ',', 'there', 'has', 'been', 'a', 'push', 'for', 'broadband', 'expansion', 'to', 'bridge', 'the', 'digital', 'divide', 'and', 'improve', 'connectivity', ',', 'especially', 'in', 'rural', 'areas', '.', 'Infrastructure', 'initiatives', 'like', 'the', 'American', 'Jobs', 'Plan', 'highlight', 'the', 'commitment', 'to', 'addressing', 'critical', 'infrastructure', 'needs', ',', 'including', 'water', 'systems', ',', 'broadband', ',', 'and', 'electric', 'vehicle', 'infrastructure', '.', 'Overall', ',', 'infrastructure', 'growth', 'in', 'the', 'U.S.', 'underscores', 'the', 'importance', 'of', 'sustainable', 'development', 'and', 'resilience', 'in', 'meeting', 'the', 'evolving', 'needs', 'of', 'society', 'and', 'the', 'economy', '.']\n"
     ]
    }
   ],
   "source": [
    "word=nltk.word_tokenize(paragraph)\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\harshiv.bhatt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming and Lemmatization with stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemm=PorterStemmer()\n",
    "for i in range(len(sentence)):\n",
    "  words=nltk.word_tokenize(sentence[i])\n",
    "  word=[stemm.stem(word)for word in words if word not in set(stopwords.words('english'))]\n",
    "  sentence[i]=' '.join(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the unit state robust histori infrastructur develop , character continu upgrad expans across key sector .',\n",
       " 'in recent year , grow emphasi revit age infrastructur , focu modern transport network , includ highway , bridg , airport .',\n",
       " 'the countri also seen invest renew energi infrastructur , wind farm solar instal , aim reduc relianc tradit fossil fuel .',\n",
       " 'addit , push broadband expans bridg digit divid improv connect , especi rural area .',\n",
       " 'infrastructur initi like american job plan highlight commit address critic infrastructur need , includ water system , broadband , electr vehicl infrastructur .',\n",
       " 'overal , infrastructur growth u.s. underscor import sustain develop resili meet evolv need societi economi .']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\harshiv.bhatt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma=WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\harshiv.bhatt\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=nltk.sent_tokenize(paragraph)\n",
    "for i in range(len(sentences)):\n",
    "  words=nltk.word_tokenize(sentences[i])\n",
    "  word=[lemma.lemmatize(word)for word in words if word not in set(stopwords.words('english'))]\n",
    "  sentences[i]=' '.join(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The United States robust history infrastructure development , characterized continuous upgrade expansion across key sector .',\n",
       " 'In recent year , growing emphasis revitalizing aging infrastructure , focus modernizing transportation network , including highway , bridge , airport .',\n",
       " 'The country also seen investment renewable energy infrastructure , wind farm solar installation , aimed reducing reliance traditional fossil fuel .',\n",
       " 'Additionally , push broadband expansion bridge digital divide improve connectivity , especially rural area .',\n",
       " 'Infrastructure initiative like American Jobs Plan highlight commitment addressing critical infrastructure need , including water system , broadband , electric vehicle infrastructure .',\n",
       " 'Overall , infrastructure growth U.S. underscore importance sustainable development resilience meeting evolving need society economy .']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now after Lemmatization it gives results in meaningful words in sentences.\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "ls=WordNetLemmatizer()\n",
    "corpus=[]\n",
    "\n",
    "for i in range(len(sentence)):\n",
    "  word=re.sub('[^a-zA-Z]',' ',sentence[i])\n",
    "  word=word.lower()\n",
    "  word=word.split()\n",
    "  word=[ls.lemmatize(w) for w in word if w  not in set(stopwords.words('english'))]\n",
    "  word=' '.join(word)\n",
    "  corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unit state robust histori infrastructur develop character continu upgrad expans across key sector',\n",
       " 'recent year grow emphasi revit age infrastructur focu modern transport network includ highway bridg airport',\n",
       " 'countri also seen invest renew energi infrastructur wind farm solar instal aim reduc relianc tradit fossil fuel',\n",
       " 'addit push broadband expans bridg digit divid improv connect especi rural area',\n",
       " 'infrastructur initi like american job plan highlight commit address critic infrastructur need includ water system broadband electr vehicl infrastructur',\n",
       " 'overal infrastructur growth u underscor import sustain develop resili meet evolv need societi economi']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to bag of word\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of word\n",
    "X=cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 3, 1, 0, 0, 1,\n",
       "        0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordToVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "text = re.sub(r'\\[[0-9]*\\]',' ',paragraph)\n",
    "text = re.sub(r'\\s+',' ',text)\n",
    "text = text.lower()\n",
    "text = re.sub(r'\\d',' ',text)\n",
    "text = re.sub(r'\\s+',' ',text)\n",
    "\n",
    "# Preparing the dataset\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [word for word in sentences[i] if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensimNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading gensim-4.3.2-cp39-cp39-win_amd64.whl (24.0 MB)\n",
      "     ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/24.0 MB 1.9 MB/s eta 0:00:13\n",
      "     --------------------------------------- 0.1/24.0 MB 919.0 kB/s eta 0:00:27\n",
      "     --------------------------------------- 0.1/24.0 MB 798.9 kB/s eta 0:00:30\n",
      "     ---------------------------------------- 0.2/24.0 MB 1.1 MB/s eta 0:00:22\n",
      "     ---------------------------------------- 0.3/24.0 MB 1.2 MB/s eta 0:00:21\n",
      "      --------------------------------------- 0.4/24.0 MB 1.4 MB/s eta 0:00:18\n",
      "      --------------------------------------- 0.5/24.0 MB 1.4 MB/s eta 0:00:18\n",
      "     - -------------------------------------- 0.7/24.0 MB 1.8 MB/s eta 0:00:14\n",
      "     - -------------------------------------- 1.0/24.0 MB 2.3 MB/s eta 0:00:11\n",
      "     -- ------------------------------------- 1.3/24.0 MB 2.6 MB/s eta 0:00:09\n",
      "     -- ------------------------------------- 1.6/24.0 MB 2.9 MB/s eta 0:00:08\n",
      "     --- ------------------------------------ 2.1/24.0 MB 3.5 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 2.5/24.0 MB 3.8 MB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 3.0/24.0 MB 4.4 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 3.5/24.0 MB 4.7 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 3.7/24.0 MB 4.8 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 4.1/24.0 MB 5.1 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 4.6/24.0 MB 5.2 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 5.1/24.0 MB 5.5 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 5.5/24.0 MB 5.7 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 5.9/24.0 MB 5.8 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 6.4/24.0 MB 6.0 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 6.7/24.0 MB 6.0 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 7.2/24.0 MB 6.2 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 7.7/24.0 MB 6.4 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 8.1/24.0 MB 6.5 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 8.5/24.0 MB 6.6 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 8.8/24.0 MB 6.4 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 9.3/24.0 MB 6.6 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 9.5/24.0 MB 6.6 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 9.8/24.0 MB 6.6 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 10.0/24.0 MB 6.5 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 10.3/24.0 MB 6.7 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 10.5/24.0 MB 7.4 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 10.8/24.0 MB 7.7 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 11.0/24.0 MB 7.8 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 11.3/24.0 MB 7.7 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 11.6/24.0 MB 7.7 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 12.0/24.0 MB 7.7 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 12.3/24.0 MB 7.7 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 12.7/24.0 MB 7.6 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 13.0/24.0 MB 7.5 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 13.5/24.0 MB 7.4 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 14.0/24.0 MB 7.4 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 14.4/24.0 MB 7.5 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 14.7/24.0 MB 7.6 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 15.0/24.0 MB 7.5 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 15.5/24.0 MB 7.5 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 15.9/24.0 MB 7.4 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 16.1/24.0 MB 7.3 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 16.5/24.0 MB 7.2 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 16.8/24.0 MB 7.3 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 17.2/24.0 MB 7.3 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 17.4/24.0 MB 7.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 17.6/24.0 MB 7.0 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 17.8/24.0 MB 6.8 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 18.1/24.0 MB 6.7 MB/s eta 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ------------------------------ --------- 18.2/24.0 MB 6.6 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 18.4/24.0 MB 6.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 18.5/24.0 MB 6.3 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 18.6/24.0 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 18.7/24.0 MB 6.0 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 19.0/24.0 MB 6.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 19.3/24.0 MB 6.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 19.6/24.0 MB 5.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 19.8/24.0 MB 5.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 20.1/24.0 MB 5.8 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 20.2/24.0 MB 5.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 20.5/24.0 MB 5.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 20.8/24.0 MB 6.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 21.1/24.0 MB 6.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 21.3/24.0 MB 5.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 21.6/24.0 MB 6.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 21.8/24.0 MB 6.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 22.0/24.0 MB 5.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 22.4/24.0 MB 5.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 22.6/24.0 MB 5.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 22.8/24.0 MB 5.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 23.1/24.0 MB 5.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 23.3/24.0 MB 5.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.7/24.0 MB 5.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  24.0/24.0 MB 5.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  24.0/24.0 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 24.0/24.0 MB 5.4 MB/s eta 0:00:00\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.2/61.2 kB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\harshiv.bhatt\\appdata\\roaming\\python\\python39\\site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\harshiv.bhatt\\anaconda3\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\harshiv.bhatt\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.15.0)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-7.0.4\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==3.8.1\n",
      "  Downloading gensim-3.8.1.tar.gz (23.4 MB)\n",
      "     ---------------------------------------- 0.0/23.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/23.4 MB 1.3 MB/s eta 0:00:19\n",
      "     --------------------------------------- 0.1/23.4 MB 518.5 kB/s eta 0:00:45\n",
      "     --------------------------------------- 0.1/23.4 MB 901.1 kB/s eta 0:00:26\n",
      "     ---------------------------------------- 0.2/23.4 MB 1.2 MB/s eta 0:00:20\n",
      "      --------------------------------------- 0.3/23.4 MB 1.3 MB/s eta 0:00:18\n",
      "      --------------------------------------- 0.4/23.4 MB 1.4 MB/s eta 0:00:17\n",
      "      --------------------------------------- 0.5/23.4 MB 1.4 MB/s eta 0:00:16\n",
      "     - -------------------------------------- 0.6/23.4 MB 1.8 MB/s eta 0:00:13\n",
      "     - -------------------------------------- 0.8/23.4 MB 1.9 MB/s eta 0:00:12\n",
      "     - -------------------------------------- 0.9/23.4 MB 2.1 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 1.1/23.4 MB 2.3 MB/s eta 0:00:10\n",
      "     -- ------------------------------------- 1.3/23.4 MB 2.3 MB/s eta 0:00:10\n",
      "     -- ------------------------------------- 1.5/23.4 MB 2.6 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.8/23.4 MB 2.7 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.9/23.4 MB 2.6 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 2.1/23.4 MB 2.7 MB/s eta 0:00:08\n",
      "     --- ------------------------------------ 2.3/23.4 MB 2.8 MB/s eta 0:00:08\n",
      "     ---- ----------------------------------- 2.5/23.4 MB 2.8 MB/s eta 0:00:08\n",
      "     ---- ----------------------------------- 2.6/23.4 MB 2.9 MB/s eta 0:00:08\n",
      "     ---- ----------------------------------- 2.9/23.4 MB 3.0 MB/s eta 0:00:07\n",
      "     ----- ---------------------------------- 3.0/23.4 MB 3.0 MB/s eta 0:00:07\n",
      "     ----- ---------------------------------- 3.2/23.4 MB 3.0 MB/s eta 0:00:07\n",
      "     ----- ---------------------------------- 3.4/23.4 MB 3.0 MB/s eta 0:00:07\n",
      "     ------ --------------------------------- 3.6/23.4 MB 3.1 MB/s eta 0:00:07\n",
      "     ------ --------------------------------- 3.9/23.4 MB 3.2 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 4.2/23.4 MB 3.4 MB/s eta 0:00:06\n",
      "     ------- -------------------------------- 4.4/23.4 MB 3.3 MB/s eta 0:00:06\n",
      "     -------- ------------------------------- 4.7/23.4 MB 3.5 MB/s eta 0:00:06\n",
      "     -------- ------------------------------- 5.0/23.4 MB 3.6 MB/s eta 0:00:06\n",
      "     -------- ------------------------------- 5.0/23.4 MB 3.5 MB/s eta 0:00:06\n",
      "     --------- ------------------------------ 5.5/23.4 MB 3.7 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 5.6/23.4 MB 3.7 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 5.8/23.4 MB 3.6 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 6.2/23.4 MB 3.8 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 6.3/23.4 MB 3.7 MB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 6.7/23.4 MB 3.9 MB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 6.8/23.4 MB 3.8 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 7.3/23.4 MB 4.0 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 7.5/23.4 MB 4.0 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 7.9/23.4 MB 4.1 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 8.1/23.4 MB 4.1 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 8.4/23.4 MB 4.1 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 8.7/23.4 MB 4.3 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 8.9/23.4 MB 4.2 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 9.3/23.4 MB 4.3 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 9.8/23.4 MB 4.4 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 10.0/23.4 MB 4.4 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 10.2/23.4 MB 4.4 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 10.5/23.4 MB 4.7 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 10.8/23.4 MB 4.9 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 11.3/23.4 MB 5.2 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 11.6/23.4 MB 5.3 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 11.9/23.4 MB 5.4 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 12.3/23.4 MB 5.6 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 12.6/23.4 MB 5.7 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 13.0/23.4 MB 5.8 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 13.4/23.4 MB 6.1 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 13.8/23.4 MB 6.3 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 14.3/23.4 MB 6.2 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 14.7/23.4 MB 6.5 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 15.1/23.4 MB 6.5 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 15.7/23.4 MB 6.8 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 15.8/23.4 MB 6.7 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 16.3/23.4 MB 6.9 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 16.7/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 17.1/23.4 MB 7.3 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 17.7/23.4 MB 7.3 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 18.1/23.4 MB 7.5 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 18.2/23.4 MB 7.4 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 18.3/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 18.6/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 19.0/23.4 MB 7.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 19.4/23.4 MB 7.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 19.8/23.4 MB 7.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 20.0/23.4 MB 7.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 20.3/23.4 MB 7.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 20.6/23.4 MB 7.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 21.0/23.4 MB 7.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 21.3/23.4 MB 7.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 21.5/23.4 MB 7.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 21.6/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 21.6/23.4 MB 6.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 21.9/23.4 MB 6.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 22.5/23.4 MB 6.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.9/23.4 MB 6.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.4/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.4/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 23.4/23.4 MB 6.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\harshiv.bhatt\\appdata\\roaming\\python\\python39\\site-packages (from gensim==3.8.1) (1.24.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\harshiv.bhatt\\anaconda3\\lib\\site-packages (from gensim==3.8.1) (1.10.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\harshiv.bhatt\\appdata\\roaming\\python\\python39\\site-packages (from gensim==3.8.1) (1.16.0)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\harshiv.bhatt\\anaconda3\\lib\\site-packages (from gensim==3.8.1) (7.0.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\harshiv.bhatt\\anaconda3\\lib\\site-packages (from smart_open>=1.8.1->gensim==3.8.1) (1.15.0)\n",
      "Building wheels for collected packages: gensim\n",
      "  Building wheel for gensim (setup.py): started\n",
      "  Building wheel for gensim (setup.py): finished with status 'done'\n",
      "  Created wheel for gensim: filename=gensim-3.8.1-cp39-cp39-win_amd64.whl size=23902859 sha256=1eca7d2478161b19aaa3ff38a1e02cd12f0fbdedfdbf8d16e2c39296ae804392\n",
      "  Stored in directory: c:\\users\\harshiv.bhatt\\appdata\\local\\pip\\cache\\wheels\\fe\\77\\24\\b3ffc86119703277a8aeb0e6914e97e216b1bd45287e41d6ba\n",
      "Successfully built gensim\n",
      "Installing collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.3.2\n",
      "    Uninstalling gensim-4.3.2:\n",
      "      Successfully uninstalled gensim-4.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\harshiv.bhatt\\\\Anaconda3\\\\Lib\\\\site-packages\\\\~ensim\\\\corpora\\\\_mmreader.cp39-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gensim==3.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Word2Vec model\n",
    "model = Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = model.wv.vocab\n",
    "# Finding Word Vectors\n",
    "vector = model.wv['war']\n",
    "\n",
    "# Most similar words\n",
    "similar = model.wv.most_similar('vikram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conversion-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
